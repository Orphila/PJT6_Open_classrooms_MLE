{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 12348 files for training.\n",
      "Found 20580 files belonging to 120 classes.\n",
      "Using 8232 files for validation.\n",
      "Noms des sous-dossiers (class_names) : ['n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog', 'n02086079-Pekinese', 'n02086240-Shih-Tzu', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02088094-Afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-Walker_hound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091032-Italian_greyhound', 'n02091134-whippet', 'n02091244-Ibizan_hound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02093428-American_Staffordshire_terrier', 'n02093647-Bedlington_terrier', 'n02093754-Border_terrier', 'n02093859-Kerry_blue_terrier', 'n02093991-Irish_terrier', 'n02094114-Norfolk_terrier', 'n02094258-Norwich_terrier', 'n02094433-Yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096294-Australian_terrier', 'n02096437-Dandie_Dinmont', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101388-Brittany_spaniel', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-Old_English_sheepdog', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106166-Border_collie', 'n02106382-Bouvier_des_Flandres', 'n02106550-Rottweiler', 'n02106662-German_shepherd', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02109961-Eskimo_dog', 'n02110063-malamute', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113023-Pembroke', 'n02113186-Cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog']\n"
     ]
    }
   ],
   "source": [
    "#Je met les liens des images d'un coté et le folder + id de l'autre\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "base_path = '/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Images'\n",
    "\n",
    "image_size = (224, 224)  # Taille images\n",
    "batch_size = 120  # Taille de lot\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_path,\n",
    "    validation_split=0.4,\n",
    "    subset=\"training\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_path,\n",
    "    validation_split=0.4,\n",
    "    subset=\"validation\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "all_classes = train_ds.class_names\n",
    "print(\"Noms des sous-dossiers (class_names) :\", all_classes)\n",
    "\n",
    "test_ds = val_ds.take(len(val_ds) // 2)\n",
    "val_ds = val_ds.skip(len(val_ds) // 2)\n",
    "\n",
    "def get_class_proportions(dataset):\n",
    "    all_labels = []\n",
    "    for _, labels in dataset.as_numpy_iterator():\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    unique_labels, label_counts = np.unique(all_labels, return_counts=True)\n",
    "    total_samples = len(all_labels)\n",
    "    class_proportions = {label: round(count / total_samples,2)*100 for label, count in zip(unique_labels, label_counts)}\n",
    "\n",
    "    return class_proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 497 files belonging to 3 classes.\n",
      "Using 299 files for training.\n",
      "Found 497 files belonging to 3 classes.\n",
      "Using 198 files for validation.\n",
      "Noms des sous-dossiers (class_names) : ['n02085620-Chihuahua', 'n02088364-beagle', 'n02099601-golden_retriever']\n",
      "Proportion des classes dans l'ensemble d'entraînement : {0: 30.0, 1: 40.0, 2: 28.999999999999996}\n",
      "Proportion des classes dans l'ensemble de validation : {0: 32.0, 1: 40.0, 2: 28.000000000000004}\n",
      "Proportion des classes dans l'ensemble de test : {0: 30.0, 1: 44.0, 2: 26.0}\n"
     ]
    }
   ],
   "source": [
    "path_2 = '/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/img'\n",
    "\n",
    "train_ds_sample = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_2,\n",
    "    validation_split=0.4,\n",
    "    subset=\"training\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds_sample = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_2,\n",
    "    validation_split=0.4,\n",
    "    subset=\"validation\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "sample_classes = train_ds_sample.class_names\n",
    "print(\"Noms des sous-dossiers (class_names) :\", sample_classes)\n",
    "\n",
    "test_ds_sample = val_ds_sample.take(len(val_ds_sample) // 2)\n",
    "val_ds_sample = val_ds_sample.skip(len(val_ds_sample) // 2)\n",
    "\n",
    "\n",
    "\n",
    "train_class_proportions = get_class_proportions(train_ds_sample)\n",
    "print(\"Proportion des classes dans l'ensemble d'entraînement :\", train_class_proportions)\n",
    "val_class_proportions = get_class_proportions(val_ds_sample)\n",
    "print(\"Proportion des classes dans l'ensemble de validation :\", val_class_proportions)\n",
    "test_class_proportions = get_class_proportions(test_ds_sample)\n",
    "print(\"Proportion des classes dans l'ensemble de test :\", test_class_proportions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du premier CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de prétraitement\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "data_augmentation_2_layers = [\n",
    "    layers.RandomZoom(0.2),\n",
    "]\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "def data_augmentation_2(images):\n",
    "    for layer in data_augmentation_2_layers:\n",
    "        images = layer(images)\n",
    "    return images\n",
    "\n",
    "#Scaling du nombre de pixels \n",
    "def data_standardisation(images):\n",
    "    \"\"\"output = (input-offset)/scale, offset à zéro\"\"\"\n",
    "    images = layers.Rescaling(scale=1.5)(images)\n",
    "    return images\n",
    "\n",
    "def convert_to_grayscale(images):\n",
    "    if images.shape[-1] == 3:\n",
    "        grayscale_images = tf.image.rgb_to_grayscale(images)\n",
    "        return grayscale_images\n",
    "    else:\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modèle 1\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "\n",
    "# Création du modèle\n",
    "model = keras.Sequential([\n",
    "    # Couches de prétraitement\n",
    "    layers.Lambda(convert_to_grayscale),\n",
    "    layers.Lambda(data_standardisation),\n",
    "    \n",
    "    # Couches de convolution et de pooling\n",
    "    Conv2D(32, (3, 3), activation='relu',input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Transition vers les couches denses\n",
    "    layers.Flatten(),\n",
    "    # Couches denses\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(120, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit, test et evaluation du 1er modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/09 18:23:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.engine.sequential.Sequential object at 0x7fe5be837190>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.engine.sequential.Sequential object at 0x7fe5be837190>, because it is not built.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model <keras.src.engine.sequential.Sequential object at 0x7fe5be837190> cannot be saved because the input shape is not available. Please specify an input shape either by calling `build(input_shape)` directly, or by calling the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mdl\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m first_cnn_from_scratch \u001b[39m=\u001b[39m train_model(model, train_ds_sample, val_ds_sample, test_ds_sample, \u001b[39m'\u001b[39;49m\u001b[39madam\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mfirst_cnn_from_scratch\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run(run_name \u001b[39m=\u001b[39m name):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m    mlflow.tensorflow.log_model(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m        model=mdl,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m        input_example=test_ens.take(1),  # Exemple d'entrée pour l'enregistrement)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     mlflow\u001b[39m.\u001b[39;49mtensorflow\u001b[39m.\u001b[39;49mlog_model(model, artifact_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcnn-model\u001b[39;49m\u001b[39m\"\u001b[39;49m,signature\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/mlflow/tensorflow/__init__.py:219\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(model, artifact_path, custom_objects, conda_env, code_paths, signature, input_example, registered_model_name, await_registration_for, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39mFLAVOR_NAME))\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[1;32m    139\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m ):\n\u001b[1;32m    154\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m    Log a TF2 core model (inheriting tf.Module) or a Keras model in MLflow Model format.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m        metadata of the logged model.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    220\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[1;32m    221\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49mtensorflow,\n\u001b[1;32m    222\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    223\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[1;32m    224\u001b[0m         code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[1;32m    225\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    226\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[1;32m    227\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    228\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[1;32m    229\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[1;32m    230\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[1;32m    231\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[1;32m    232\u001b[0m         saved_model_kwargs\u001b[39m=\u001b[39;49msaved_model_kwargs,\n\u001b[1;32m    233\u001b[0m         keras_model_kwargs\u001b[39m=\u001b[39;49mkeras_model_kwargs,\n\u001b[1;32m    234\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    235\u001b[0m     )\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/mlflow/models/model.py:622\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m     (tracking_uri \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdatabricks\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m get_uri_scheme(tracking_uri) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdatabricks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    618\u001b[0m     \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m     \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minput_example\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    620\u001b[0m ):\n\u001b[1;32m    621\u001b[0m     _logger\u001b[39m.\u001b[39mwarning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)\n\u001b[0;32m--> 622\u001b[0m flavor\u001b[39m.\u001b[39;49msave_model(path\u001b[39m=\u001b[39;49mlocal_path, mlflow_model\u001b[39m=\u001b[39;49mmlflow_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    623\u001b[0m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39martifact_path, run_id)\n\u001b[1;32m    624\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/mlflow/tensorflow/__init__.py:443\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, path, conda_env, code_paths, mlflow_model, custom_objects, signature, input_example, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)\u001b[0m\n\u001b[1;32m    441\u001b[0m         shutil\u001b[39m.\u001b[39mcopy2(src\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39mname, dst\u001b[39m=\u001b[39mmodel_path)\n\u001b[1;32m    442\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     model\u001b[39m.\u001b[39;49msave(model_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeras_model_kwargs)\n\u001b[1;32m    445\u001b[0m pyfunc_options \u001b[39m=\u001b[39m {\n\u001b[1;32m    446\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data_subpath,\n\u001b[1;32m    447\u001b[0m }\n\u001b[1;32m    449\u001b[0m flavor_options \u001b[39m=\u001b[39m {\n\u001b[1;32m    450\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpyfunc_options,\n\u001b[1;32m    451\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m: _MODEL_TYPE_KERAS,\n\u001b[1;32m    452\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkeras_version\u001b[39m\u001b[39m\"\u001b[39m: tf\u001b[39m.\u001b[39m__version__,\n\u001b[1;32m    453\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msave_format\u001b[39m\u001b[39m\"\u001b[39m: save_format,\n\u001b[1;32m    454\u001b[0m }\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/saving/legacy/saving_utils.py:88\u001b[0m, in \u001b[0;36mraise_model_input_error\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_model_input_error\u001b[39m(model):\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential):\n\u001b[0;32m---> 88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m cannot be saved because the input shape is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mavailable. Please specify an input shape either by calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`build(input_shape)` directly, or by calling the model on actual \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdata using `Model()`, `Model.fit()`, or `Model.predict()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     95\u001b[0m     \u001b[39m# If the model is not a `Sequential`, it is intended to be a subclassed\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# model.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m cannot be saved either because the input shape is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mavailable or because the forward pass of the model is not defined.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Model <keras.src.engine.sequential.Sequential object at 0x7fe5be837190> cannot be saved because the input shape is not available. Please specify an input shape either by calling `build(input_shape)` directly, or by calling the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`."
     ]
    }
   ],
   "source": [
    "# 1er modèle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "def train_model(mdl, train_ens, val_ens, test_ens, optimizer,name):\n",
    "    class_ens = train_ens.class_names\n",
    "    mdl.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # Commencer une expérience MLflow\n",
    "    with mlflow.start_run(run_name = name):\n",
    "        \"\"\"\n",
    "        mlflow.tensorflow.log_model(\n",
    "            model=mdl,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=\"cnn \"+name,\n",
    "            input_example=test_ens.take(1),  # Exemple d'entrée pour l'enregistrement)\n",
    "        \"\"\"\n",
    "        mlflow.tensorflow.log_model(model, artifact_path=\"cnn-model\",input_example=test_ens.take(1),signature=False)\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"epochs\", 3)\n",
    "\n",
    "        mdl.fit(train_ens, validation_data=val_ens, epochs=3)\n",
    "        # Prédiction pour l'ensemble de test\n",
    "        y_pred = mdl.predict(test_ens)\n",
    "        # Convertir les prédictions en classes\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        # Convertir les étiquettes de l'ensemble de test en classes\n",
    "        y_true = np.concatenate([y for x, y in test_ens], axis=0)\n",
    "        \"\"\"\n",
    "        # Calculer la matrice de confusion\n",
    "        cm = confusion_matrix(y_true, y_pred_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, cmap=\"Reds\",xticklabels=class_ens, yticklabels=class_ens)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Matrice de Confusion - Ensemble de Test')\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        # Évaluer l'exactitude sur l'ensemble de test\n",
    "        accuracy = mdl.evaluate(test_ens, verbose=0)[1]\n",
    "        print(f\"Précision sur le test: {accuracy}\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    return mdl\n",
    "\n",
    "\n",
    "first_cnn_from_scratch = train_model(model, train_ds_sample, val_ds_sample, test_ds_sample, 'adam',\"first_cnn_from_scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amélioration du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 14s 4s/step - loss: 39.8289 - accuracy: 0.1739 - val_loss: 31.3713 - val_accuracy: 0.3590\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 14s 4s/step - loss: 15.2642 - accuracy: 0.3579 - val_loss: 1.9805 - val_accuracy: 0.2436\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 13s 4s/step - loss: 2.0120 - accuracy: 0.3478 - val_loss: 1.6176 - val_accuracy: 0.2821\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Précision sur le test: 0.3083333373069763\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.Sequential([\n",
    "    # Couches de prétraitement\n",
    "    layers.Lambda(convert_to_grayscale),\n",
    "    layers.Lambda(data_standardisation),\n",
    "    layers.Lambda(data_augmentation),\n",
    "\n",
    "    # Couches de convolution et de pooling\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Transition vers les couches denses\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Couches denses\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),  # Ajout d'une couche de dropout pour la régularisation\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),  # Ajout d'une autre couche de dropout\n",
    "    layers.Dense(120, activation='softmax') \n",
    "])\n",
    "\n",
    "cnn_with_data_augmentation = train_model(model_2,train_ds_sample,val_ds_sample, test_ds_sample,'adam',\"cnn_with_data_augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout de la 2eme data augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 17s 4s/step - loss: 63.1546 - accuracy: 0.0502 - val_loss: 1.9580 - val_accuracy: 0.4231\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 13s 4s/step - loss: 5.2117 - accuracy: 0.2007 - val_loss: 1.4058 - val_accuracy: 0.3590\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 13s 4s/step - loss: 2.3992 - accuracy: 0.3378 - val_loss: 1.3036 - val_accuracy: 0.3462\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Précision sur le test: 0.4333333373069763\n"
     ]
    }
   ],
   "source": [
    "model_2_1 = keras.Sequential([\n",
    "    # Couches de prétraitement\n",
    "    layers.Lambda(convert_to_grayscale),\n",
    "    layers.Lambda(data_standardisation),\n",
    "    layers.Lambda(data_augmentation),\n",
    "    layers.Lambda(data_augmentation_2),\n",
    "\n",
    "    # Couches de convolution et de pooling\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Transition vers les couches denses\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Couches denses\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout d'une couche de dropout pour la régularisation\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout d'une autre couche de dropout\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout d'une autre couche de dropout\n",
    "    layers.Dense(120, activation='softmax') \n",
    "])\n",
    "\n",
    "cnn_with_data_augmentation_2 = train_model(model_2_1,train_ds_sample,val_ds_sample,test_ds_sample,\"adam\",\"cnn_with_data_augmentation_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation des hyperparamètres avec optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 17:50:46,587] A new study created in memory with name: no-name-4a6fd0ba-96e1-4035-94c2-948463468761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 880ms/step - loss: 4.6415 - accuracy: 0.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 17:52:01,231] Trial 0 finished with value: 0.26923078298568726 and parameters: {'dropout_rate': 0.2690204970671646, 'learning_rate': 0.007577897859527736, 'num_epochs': 6}. Best is trial 0 with value: 0.26923078298568726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.0790 - accuracy: 0.4231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 17:54:27,509] Trial 1 finished with value: 0.42307692766189575 and parameters: {'dropout_rate': 0.29879410947390456, 'learning_rate': 0.004114869825661203, 'num_epochs': 8}. Best is trial 1 with value: 0.42307692766189575.\n",
      "[W 2024-02-09 17:55:57,488] Trial 2 failed with parameters: {'dropout_rate': 0.23512701347961015, 'learning_rate': 0.003382643919374594, 'num_epochs': 7} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/_l/cjjst_c50lx2nkkr280zbp440000gp/T/ipykernel_1306/1786292663.py\", line 48, in objective\n",
      "    model.fit(train_ds_sample, validation_data=val_ds_sample, epochs=num_epochs, verbose=0)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
      "    outputs = execute.execute(\n",
      "  File \"/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2024-02-09 17:55:57,491] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Création de l'étude Optuna\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Affichage des résultats\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials))\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Entraînement du modèle\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds_sample, validation_data\u001b[39m=\u001b[39;49mval_ds_sample, epochs\u001b[39m=\u001b[39;49mnum_epochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Évaluation du modèle sur l'ensemble de validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/orphila_adjovi/PJT6_Open_classrooms_MLE/Adjovi_Orphila_2_notebook_model_perso_022024.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m _, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(val_ds_sample)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/PJT6_Open_classrooms_MLE/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def objective(trial):\n",
    "    # Paramètres à optimiser\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 5, 10)\n",
    "\n",
    "    # Création du modèle avec les paramètres suggérés\n",
    "    model = keras.Sequential([\n",
    "        # Couches de prétraitement\n",
    "        layers.Lambda(convert_to_grayscale),\n",
    "        layers.Lambda(data_standardisation),\n",
    "        layers.Lambda(data_augmentation),\n",
    "        layers.Lambda(data_augmentation_2),\n",
    "\n",
    "        # Couches de convolution et de pooling\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Transition vers les couches denses\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Couches denses\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(120, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    # Compilation du modèle avec l'optimiseur Adam et le taux d'apprentissage\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    model.fit(train_ds_sample, validation_data=val_ds_sample, epochs=num_epochs, verbose=0)\n",
    "\n",
    "    # Évaluation du modèle sur l'ensemble de validation\n",
    "    _, accuracy = model.evaluate(val_ds_sample)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Création de l'étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Affichage des résultats\n",
    "print('Number of finished trials: ', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value: ', trial.value)\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 19s 4s/step - loss: 21.7162 - accuracy: 0.1973 - val_loss: 4.1623 - val_accuracy: 0.3077\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 5.7491 - accuracy: 0.3512 - val_loss: 1.4556 - val_accuracy: 0.3718\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 1.8416 - accuracy: 0.3679 - val_loss: 1.4318 - val_accuracy: 0.4359\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.6640 - accuracy: 0.4013 - val_loss: 1.3193 - val_accuracy: 0.3718\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 14s 4s/step - loss: 1.5037 - accuracy: 0.3612 - val_loss: 1.0844 - val_accuracy: 0.4103\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.3856 - accuracy: 0.3746 - val_loss: 1.1378 - val_accuracy: 0.4103\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.4019 - accuracy: 0.3445 - val_loss: 1.0947 - val_accuracy: 0.4359\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.3924 - accuracy: 0.3411 - val_loss: 1.1777 - val_accuracy: 0.3590\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.2638 - accuracy: 0.3946 - val_loss: 1.1377 - val_accuracy: 0.3205\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.2927 - accuracy: 0.4214 - val_loss: 1.1754 - val_accuracy: 0.5000\n",
      "WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa8ec7800d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur le test: 0.44999998807907104\n"
     ]
    }
   ],
   "source": [
    "#modèle optimisé\n",
    "dropout_rate = 0.2570433990346258\n",
    "learning_rate = 0.0005703961594509845\n",
    "\n",
    "model_3 = keras.Sequential([\n",
    "    # Couches de prétraitement\n",
    "    layers.Lambda(convert_to_grayscale),\n",
    "    layers.Lambda(data_standardisation),\n",
    "    layers.Lambda(data_augmentation),\n",
    "    layers.Lambda(data_augmentation_2),\n",
    "\n",
    "    # Couches de convolution et de pooling\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Transition vers les couches denses\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Couches denses\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_rate),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_rate),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_rate),\n",
    "    layers.Dense(120, activation='softmax') \n",
    "])\n",
    "\n",
    "cnn_from_scratch_optimized = train_model(model_3,train_ds_sample,val_ds_sample,test_ds_sample,Adam(learning_rate=learning_rate),\"cnn_from_scratch_optimized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
